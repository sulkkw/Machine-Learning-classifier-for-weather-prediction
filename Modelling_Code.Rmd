---
title: "KoKoWin31842305"
author: "Ko Ko Win"
date: "5/1/2022"
output: html_document
---
```{r}
#load libraries 
library(pastecs)
library(tree)
library(rpart)
library(e1071)
library(adabag)
library(randomForest)
library(ROCR)
library(sf)
```


```{r}
rm(list = ls())
WAUS <- read.csv("WarmerTomorrow2022.csv", stringsAsFactors = T)
L <- as.data.frame(c(1:49))
set.seed(31842305) # Your Student ID is the random seed
L <- L[sample(nrow(L), 10, replace = FALSE),] # sample 10 locations
WAUS <- WAUS[(WAUS$Location %in% L),]
WAUS <- WAUS[sample(nrow(WAUS), 2000, replace = FALSE),] # sample 2000 rows
```



```{r}
df_stat_sum <-  subset(WAUS, select = -c(1,2,3,4,10,12,13,24))
skim(df_stat_sum)

WAUS

```

Omit rows with NA and set target variable to factor
```{r}
WAUS = na.omit(WAUS)
WAUS$WarmerTomorrow = as.factor(WAUS$WarmerTomorrow)
```

# 1)
```{r}
warm_tmr = as.data.frame(table(WAUS$WarmerTomorrow))
warmer =  round((warm_tmr[2,2] / sum(warm_tmr[,2])) * 100, digits = 2) #52.43
cooler = round((warm_tmr[1,2] / sum(warm_tmr[,2])) * 100, digits = 2) # 47.57
```

#### Question: What is the proportion of days when it is warmer than the previous day compared to those where it is cooler?

#### Answer: According to the observation of data proportion of the days when it is warmer than the previous day is 52.43%. On the other hand, proportion of days where it is cooler than previous day is 47.57%. We can see that proportion of warmer days are higher than cooler days. 


```{r}
df_summary <- subset(WAUS, select = -c(1,2,3,4,10,12,13,24))
df_summary = round(stat.desc(df_summary), digits = 2)
df_summary
```

#### Question: Is there anything noteworthy in the data? Are there any attributes you need to consider omitting from your analysis?

#### Answer: To check the summary description of the predictors i have disregarded some columns which is not needed. From the table obtained above we can see that mean and median values for all the variables are identical which shows that there is no data skew and the data is symmetrical. I have already omitted rows with NA values. 

#2) 

#### Question: Document any pre-processing required to make the data set suitable for the model fitting that follows

#### Answer: The data has 41202 missing values so I have ommitted all the rows with NA values and i have changed the class of the target variable WarmerTomorrow to a factor for the model fitting in upcoming questions. This question was already done before proceeding to Q1. 

#3) 

#### Divide your data into a 70% training and 30% test

```{r}
set.seed(31842305)
train.row = sample(1:nrow(WAUS), 0.7*nrow(WAUS))
train.data = WAUS[train.row,]
test.data = WAUS[-train.row,]
```


#4) 

#### Question: Implement a classification model using each of the following techniques

Decision Tree 
```{r}
tree.fit = tree(WarmerTomorrow ~., data = train.data)
```

Naïve Bayes
```{r}
naive.fit = naiveBayes(WarmerTomorrow ~., data = train.data)
```

Bagging 
```{r}
wbag.fit = bagging(WarmerTomorrow ~., train.data, mfinal = 10)
```

Boosting 
```{r}
wboost.fit = boosting(WarmerTomorrow ~., train.data, mfinal = 10)
```

Random Forest 
```{r}
rf.fit = randomForest(WarmerTomorrow ~., train.data)
```


#5) 

#### Question: Using the test data, classify each of the test cases as ‘warmer tomorrow’ or ‘not warmer tomorrow’. Create a confusion matrix and report the accuracy of each model.

Decision Tree
```{r}
tree.pred = predict(tree.fit, test.data, type = "class")
#confusion matrix
tree.cfm = table(actual = test.data$WarmerTomorrow, predicted = tree.pred)
tree.acc = round(mean(tree.pred == test.data$WarmerTomorrow)*100, digits = 2)
cat("Decision Tree accuracy is: ", tree.acc, "%")
```


Naïve Bayes
```{r}
naive.pred = predict(naive.fit, test.data)
#confusion matrix
naive.cfm = table(actual = test.data$WarmerTomorrow, predicted = naive.pred)
naive.acc = round(mean(naive.pred == test.data$WarmerTomorrow)*100, digits = 2)
cat("Naïve Bayes model accuracy is: ", naive.acc, "%")
```


Bagging 
```{r}
wbag.fit_pred = predict.bagging(wbag.fit, test.data)
#confusion matrix
wbag.fit.cfm = wbag.fit_pred$confusion
wbag.fit.acc = round(mean(wbag.fit_pred$class == test.data$WarmerTomorrow)*100, digits = 2)
cat("Bagging ensemble model accuracy is: ", wbag.fit.acc, "%")
```


Boosting
```{r}
wboost.fit_pred = predict.boosting(wboost.fit, test.data)
#confusion matrix
wboost.fit.cfm = wboost.fit_pred$confusion
wboost.fit.acc = round(mean(wboost.fit_pred$class == test.data$WarmerTomorrow)*100, digits = 2)
cat("Boosting ensemble model accuracy is: ", wboost.fit.acc, "%")
```

Random Forest 
```{r}
rf.fit_pred = predict(rf.fit, test.data)
#confusion matrix
rf.fit.cfm = tree.cfm = table(actual = test.data$WarmerTomorrow, predicted = rf.fit_pred)
rf.fit.acc = round(mean(rf.fit_pred == test.data$WarmerTomorrow)*100, digits = 2)
cat("Random Forest ensemble model accuracy is: ", rf.fit.acc, "%")
```

#6) 
#### Question: Calculate confidence and construct ROC curve

Decision Tree 
```{r}
tree.conf = predict(tree.fit, test.data, type = "vector")
tree.conf.pred = prediction(tree.conf[,2], test.data$WarmerTomorrow)
tree.perf = performance(tree.conf.pred, "tpr", "fpr")
plot(tree.perf, col = "black") + abline(0,1)

```

Naïve Bayes
```{r}
naive.conf = predict(naive.fit, test.data, type = "raw")
naive.conf.pred = prediction(naive.conf[,2], test.data$WarmerTomorrow)
naive.perf = performance(naive.conf.pred, "tpr", "fpr")
plot(naive.perf,add = TRUE, col = "blueviolet")
```

Bagging 
```{r}
bag.conf = prediction(wbag.fit_pred$prob[,2], test.data$WarmerTomorrow) 
bag.perf = performance(bag.conf, "tpr", "fpr") 
plot(bag.perf, col = "green") + abline(0,1)
```

Boosting 
```{r}
boost.conf = prediction(wboost.fit_pred$prob[,2], test.data$WarmerTomorrow) 
boost.perf = performance(boost.conf, "tpr", "fpr")
plot(boost.perf, col ="red") + abline(0,1)
```

Random Forest 
```{r}
rf.conf = predict(rf.fit, test.data, type = "prob")
rf.conf.pred = prediction(rf.conf[,2], test.data$WarmerTomorrow)
rf.perf = performance(rf.conf.pred, "tpr", "fpr")
plot(rf.perf, col = "cyan") + abline(0,1)
```




```{r}
knitr::purl()
```


